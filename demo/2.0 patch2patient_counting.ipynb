{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import openpyxl\n",
    "from PIL import Image\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import os ,sys\n",
    "import numpy as np\n",
    "# checkpoint = torch.load('D:/dataset_Huo_1/output/resnet18_1-1704.pth',map_location='cpu')\n",
    "# checkpoint = checkpoint['state_dict']\n",
    "model = timm.create_model(model_name='resnet18',num_classes = 2,checkpoint_path=path_to_patch-level_models)\n",
    "# params=model.state_dict()\n",
    "# for k,v in checkpoint.items():\n",
    "#     print(k) #只打印key值，不打印具体参数。\n",
    "# model.load_state_dict(checkpoint,strict=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchFile(key,startPath = '.'):\n",
    "    if not os.path.isdir(startPath):\n",
    "        raise ValueError\n",
    "    l= [os.path.join(startPath,x) for x in os.listdir(startPath)]  #列出所有文件的绝对路径\n",
    "    #listdir出来的相对路径 不能用于 isfile  abspath只能用在当前目录\n",
    "    filelist=[x for x in l if os.path.isfile(x) if key in os.path.splitext(os.path.basename(x))[0]] #文件\n",
    "    #只查找文件名中  不包括后缀 文件路径\n",
    "    if not hasattr(searchFile,'basePath'):#把函数当成类 添加属性\n",
    "        searchFile.basePath=startPath #只有第一次调用才会赋值给basePath\n",
    "    outmap = map(lambda x:os.path.relpath(x,searchFile.basePath),filelist) #转换成相对于初始路径的相对路径\n",
    "\n",
    "    outlist = list(outmap) \n",
    "\n",
    "    dirlist= [x for x in l if os.path.isdir(x)]  #目录\n",
    "    for dir in dirlist:\n",
    "        outlist = outlist + searchFile(key,dir)\n",
    " \n",
    "    return outlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the files named path_to_names_of_patients are placed in the folder /MAg/name_patient/\n",
    "info = openpyxl.load_workbook(path_to_names_of_patients)\n",
    "inf = info.active\n",
    "# number = openpyxl.load_workbook('D:/dataset_Huo_1/MSIMUT_train.xlsx')\n",
    "# num = number.active\n",
    "from openpyxl import Workbook\n",
    "wb = Workbook()\n",
    "sheet = wb.active\n",
    "sheet.title = \"MSI_patient_data\"\n",
    "\n",
    "feature_MSI = Workbook()\n",
    "sheet2 = feature_MSI.active\n",
    "sheet2.title = \"feature_MSI\"\n",
    "\n",
    "patch_info = Workbook()\n",
    "sheet3 = patch_info.active\n",
    "sheet.title = \"patch_info\"\n",
    "\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)\n",
    "right_num = 0\n",
    "vote=[]\n",
    "# Please adjust the parameters of the for loop according to the number of patients in each set\n",
    "for i in range(0,12):\n",
    "    patient_name = inf.cell(row=1, column=(i+1)).value\n",
    "    print(i,\"patient id:\",patient_name)\n",
    "    sheet[\"A%d\" % (i+1)].value = patient_name\n",
    "    # image_num = inf.cell(i+1,1).value\n",
    "    file_names = searchFile(patient_name,startPath = path_images)\n",
    "    image_num = len(file_names)\n",
    "    print(\"numbers of images of this patient\",image_num)\n",
    "    pred_MSS = 0\n",
    "    pred_MSI = 0\n",
    "    patient_patch = []\n",
    "    if image_num:\n",
    "        for j in range(image_num):\n",
    "            path = 'D:/dataset_Huo_4/STAD/validation/MSIMUT/' + file_names[j] #filename of images\n",
    "            image = Image.open(path).convert('RGB')\n",
    "            tensor = transform(image).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                out = model(tensor)\n",
    "            probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
    "            probabilities = np.array(probabilities)\n",
    "            if probabilities[0] >= probabilities[1]:\n",
    "                pred_MSI = pred_MSI + 1\n",
    "            elif probabilities[0] < probabilities[1]:\n",
    "                pred_MSS = pred_MSS + 1\n",
    "            sheet3.cell(j+1,i+1).value = probabilities[0]\n",
    "            patient_patch.append(probabilities[0])\n",
    "            # print(j,'current patch:',probabilities[0])\n",
    "        counts,bins = np.histogram(patient_patch,bins = 10,range = (0,1))\n",
    "        counts_norm = counts / image_num\n",
    "        for t in range(10):\n",
    "            sheet2.cell(i+1,t+1).value = counts_norm[t]\n",
    "        vote_buf = pred_MSI / (pred_MSI + pred_MSS)\n",
    "        sheet2.cell(i+1,11).value = vote_buf\n",
    "        sheet2.cell(i+1,12).value = 1\n",
    "        if vote_buf >= 0.5:\n",
    "            right_num = right_num + 1\n",
    "        vote.append(vote_buf)\n",
    "        print(i, \"pred_MSI:\",pred_MSI,\"pred_MSS:\",pred_MSS,\"vote_MSI:\",vote[i],\"mean vote:\",sum(vote)/(i+1))\n",
    "        print(\"\\n\")\n",
    "        sheet[\"B%d\" % (i+1)].value = vote[i]\n",
    "        sheet[\"C%d\" % (i+1)].value = pred_MSI\n",
    "        sheet[\"D%d\" % (i+1)].value = pred_MSS\n",
    "print('total number: 12','right number:',right_num)\n",
    "# wb.save('D:/dataset_Huo_4/resnet18_0925/MSI_classfication.xlsx')\n",
    "feature_MSI.save(path_to_hist_features)\n",
    "patch_info.save(path_to_results_of_patches)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa88eb80fe6aea0a2f4aff8fa8849bac35c0cecd21d1c3c7c22b82a5cf54fb2a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tf2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
